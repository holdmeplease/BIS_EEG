{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对比不同feature区分有意识和无意识状态的能力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 抓取LOC和ROC\n",
    "# 0428: 在event这一行中精确到s，虽然LOC精确到s，但是诱导给药的精度是m，因此LOC的实际精度还是m\n",
    "# 0516: 在event这一行中精确到s，精度同上\n",
    "# 0517: 在event这一行中精确到m\n",
    "# 0518: 在event这一行中精确到m\n",
    "# 0519: 在event这一行中精确到m\n",
    "# 0523～0526: 在event表格中有专门记载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import mne\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "from bis_lib import *\n",
    "from bis_lib_ML import feature_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可以使用supervised learning进一步提升区分C和NC状态的能力\n",
    "# feature: PE + LZC + (SVD)\n",
    "# label: C/NC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fft import fft\n",
    "from scipy.signal import blackman, hamming, detrend\n",
    "def get_bispectrum(eeg_data):\n",
    "    L = 1\n",
    "    w = hamming(eeg_data.shape[-1])\n",
    "    ywf = fft(w * detrend(eeg_data, type='constant'))\n",
    "    print(ywf.shape)\n",
    "    bispectrum = np.zeros((ywf.shape[0], ywf.shape[1], ywf.shape[2]//2, ywf.shape[2]//2))\n",
    "    for i in range(bispectrum.shape[-2]):\n",
    "        for j in range(bispectrum.shape[-1]):\n",
    "            bispectrum[:,:,i,j] = np.abs(ywf[:,:,i] * ywf[:,:,j] * np.conj(ywf[:,:,i+j]))\n",
    "    return bispectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trispectrum(eeg_data):\n",
    "    L = 1\n",
    "    w = hamming(eeg_data.shape[-1])\n",
    "    ywf = fft(w * detrend(eeg_data, type='constant'))\n",
    "    print('ywf.shape', ywf.shape)\n",
    "    trispectrum = np.zeros((ywf.shape[0], ywf.shape[1], ywf.shape[2]//3, ywf.shape[2]//3, ywf.shape[2]//3))\n",
    "    for i in range(trispectrum.shape[-3]):\n",
    "        for j in range(trispectrum.shape[-2]):\n",
    "            for k in range(trispectrum.shape[-1]):\n",
    "                trispectrum[:,:,i,j,k] = np.abs(ywf[:,:,i] * ywf[:,:,j] * ywf[:,:,k] * \n",
    "                                                np.conj(ywf[:,:,i+j]) * np.conj(ywf[:,:,i+k]) * np.conj(ywf[:,:,j+k]) * ywf[:,:,i+j+k])\n",
    "    return trispectrum\n",
    "trispectrum = get_trispectrum(eeg_data)\n",
    "print(trispectrum.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info = {}\n",
    "draw_c_nc = {}\n",
    "xy_learning = {}\n",
    "feature_clean = True\n",
    "fs = 1000\n",
    "exp_dates = ['0428', '0516', '0517', '0518', '0519', '0523', '0524', '0525', '0526']\n",
    "\n",
    "for exp_date in exp_dates:\n",
    "# for exp_date in ['0526']:\n",
    "    path_root = '/Users/zhangchao/Downloads/data_tmp/{}'.format(exp_date)\n",
    "    exp = get_exp(path_root, exp_date)\n",
    "    eeg_start_time, eeg_end_time = get_eeg_time(path_root, exp)\n",
    "    csv_path = '../csv_files/{}'.format(exp_date)\n",
    "    for i in range(len(exp)):\n",
    "    # for i in range(1):\n",
    "        eeg = csv2eeg(path_root, exp[i])\n",
    "        print('eeg.shape', eeg.shape)\n",
    "        print('duration(s):', eeg.shape[1]/fs)\n",
    "        data_info['exp{}_duration'.format(i)] = eeg.shape[1]/fs\n",
    "        tmp = datetime.strptime(eeg_end_time[i], '%Y-%m-%d %H:%M:%S') - datetime.strptime(eeg_start_time[i], '%Y-%m-%d %H:%M:%S')\n",
    "        data_info['exp{}_pack_loss'.format(i)] = tmp.seconds - eeg.shape[1]/fs\n",
    "\n",
    "        ch_num = eeg.shape[0]\n",
    "        # for mne object\n",
    "        ch_names = ['EEG{}'.format(j) for j in range(ch_num)]\n",
    "        ch_types = ['eeg' for i in range(ch_num)]\n",
    "        info = mne.create_info(ch_names, ch_types=ch_types, sfreq=fs)\n",
    "        print(info)\n",
    "\n",
    "        data_info['exp{}_chnum'.format(i)] = eeg.shape[0]\n",
    "        data_info['exp{}_filename'.format(i)] = exp[i]\n",
    "\n",
    "        my_raw = mne.io.RawArray(eeg, info)\n",
    "        my_raw.filter(l_freq=0.5, h_freq=30)\n",
    "        # draw_eeg_psd(my_raw, ch_names, exp[i])\n",
    "\n",
    "        if exp_date in ['0523', '0524', '0525', '0526']:\n",
    "            xls_info = process_xls_new(csv_path, exp_id=i, eeg_start_time=eeg_start_time, eeg_end_time=eeg_end_time)\n",
    "        else:\n",
    "            xls_info = process_xls(csv_path, exp_id=i, eeg_start_time=eeg_start_time, eeg_end_time=eeg_end_time)\n",
    "            \n",
    "        eeg_data = eeg_segment(my_raw[:][0], fs, seg_length=60, eeg_start_time=eeg_start_time[i])\n",
    "\n",
    "        eeg_feature_dict = {}\n",
    "        if feature_clean:\n",
    "            pe = np.load('../npy_files/feature_clean/PE_{}_{}.npy'.format(exp_date, exp[i]))\n",
    "            # se = np.load('../npy_files/feature_clean/SE_{}_{}.npy'.format(exp_date, exp[i]))\n",
    "            lzc = np.load('../npy_files/feature_clean/LZC_{}_{}.npy'.format(exp_date, exp[i]))\n",
    "            svd = np.load('../npy_files/feature_clean/SVD_{}_{}.npy'.format(exp_date, exp[i]))\n",
    "        else:\n",
    "            pe = np.load('../npy_files/PE_{}_{}.npy'.format(exp_date, exp[i]))\n",
    "            # se = np.load('../npy_files/SE_{}_{}.npy'.format(exp_date, exp[i]))\n",
    "            lzc = np.load('../npy_files/LZC_{}_{}.npy'.format(exp_date, exp[i]))\n",
    "            svd = np.load('../npy_files/SVD_{}_{}.npy'.format(exp_date, exp[i]))\n",
    "\n",
    "        eeg_feature_dict['PE'] = np.mean(pe, axis=1)\n",
    "        # eeg_feature_dict['SE'] = np.mean(pe, axis=1)\n",
    "        eeg_feature_dict['LZC'] = np.mean(lzc, axis=1)\n",
    "        eeg_feature_dict['SVD_0'] = svd[0,:]\n",
    "        eeg_feature_dict['SVD_1'] = svd[1,:]\n",
    "        eeg_feature_dict['SVD_2'] = svd[2,:]\n",
    "        eeg_feature_dict['SVD_3'] = svd[3,:]\n",
    "\n",
    "        # draw_results(exp_date, exp[i], xls_info, eeg_feature_dict)\n",
    "        for key in eeg_feature_dict.keys():\n",
    "            draw_c_nc['{}_{}_{}_c'.format(key, exp_date, exp[i])], draw_c_nc['{}_{}_{}_nc'.format(key, exp_date, exp[i])], xy_learning['{}_{}_{}_feature'.format(key, exp_date, exp[i])], xy_learning['{}_{}_{}_label'.format(key, exp_date, exp[i])] = draw_discrimination(eeg_feature_dict, xls_info, key, exp_date, exp[i])\n",
    "        key = 'bis'\n",
    "        draw_c_nc['{}_{}_{}_c'.format(key, exp_date, exp[i])], draw_c_nc['{}_{}_{}_nc'.format(key, exp_date, exp[i])], xy_learning['{}_{}_{}_feature'.format(key, exp_date, exp[i])], xy_learning['{}_{}_{}_label'.format(key, exp_date, exp[i])] = draw_discrimination(eeg_feature_dict, xls_info, key, exp_date, exp[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据不同的任务，有不同的被试数据需要舍弃\n",
    "# 目前feature是在这个函数里面选择的\n",
    "# 因此，方便起见，这个函数没有写进*_lib.py里\n",
    "def get_model_data(exp_date_test, exp_idx_test):\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    test_x = []\n",
    "    test_y = []\n",
    "    # key_bkp = ['PE', 'LZC', 'SVD_0', 'SVD_1', 'SVD_2', 'SVD_3']\n",
    "    # key_bkp = ['bis']\n",
    "    # key_bkp = ['PE']\n",
    "    # key_bkp = ['LZC']\n",
    "    # key_bkp = ['SVD_0']\n",
    "    # key_bkp = ['SVD_1']\n",
    "    # key_bkp = ['SVD_2']\n",
    "    key_bkp = ['SVD_3']\n",
    "    for exp_date in exp_dates:\n",
    "        path_root = '/Users/zhangchao/Downloads/data_tmp/{}'.format(exp_date)\n",
    "        exp = get_exp(path_root, exp_date)\n",
    "        eeg_start_time, eeg_end_time = get_eeg_time(path_root, exp)\n",
    "        csv_path = '../csv_files/{}'.format(exp_date)\n",
    "        for i in range(len(exp)):\n",
    "            for j in range(len(xy_learning['{}_{}_{}_feature'.format(key_bkp[0], exp_date, exp[i])])):\n",
    "                tmp = []\n",
    "                for key in key_bkp:\n",
    "                    tmp.append(xy_learning['{}_{}_{}_feature'.format(key, exp_date, exp[i])][j])\n",
    "                if exp_date==exp_date_test and i==exp_idx_test:\n",
    "                    test_x.append(tmp)\n",
    "                    test_y.append(xy_learning['{}_{}_{}_label'.format(key_bkp[0], exp_date, exp[i])][j])      \n",
    "                else:      \n",
    "                    train_x.append(tmp)\n",
    "                    train_y.append(xy_learning['{}_{}_{}_label'.format(key_bkp[0], exp_date, exp[i])][j])\n",
    "    train_x = np.array(train_x)\n",
    "    train_y = np.array(train_y)\n",
    "    test_x = np.array(test_x)\n",
    "    test_y = np.array(test_y)\n",
    "    print('train_x.shape', train_x.shape)\n",
    "    print('test_x.shape', test_x.shape)\n",
    "    print('train_y.shape', train_y.shape)\n",
    "    print('test_y.shape', test_y.shape)\n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_list = []\n",
    "f1_list = []\n",
    "for exp_date in exp_dates:\n",
    "    path_root = '/Users/zhangchao/Downloads/data_tmp/{}'.format(exp_date)\n",
    "    exp = get_exp(path_root, exp_date)\n",
    "    for i in range(len(exp)): \n",
    "        train_x, train_y, test_x, test_y = get_model_data(exp_date_test=exp_date, exp_idx_test=i)\n",
    "        train_x, test_x = feature_norm(train_x, test_x)\n",
    "        clf = SVC(kernel='rbf', max_iter=1000000, class_weight='balanced')\n",
    "        clf.fit(train_x, train_y)\n",
    "        acc_list.append(accuracy_score(test_y, clf.predict(test_x))) \n",
    "        f1_list.append(f1_score(test_y, clf.predict(test_x)))\n",
    "print('mean(acc):{:.3f}'.format(np.mean(np.array(acc_list))))\n",
    "print('mean(f1):{:.3f}'.format(np.mean(np.array(f1_list))))\n",
    "print('std(acc):{:.3f}'.format(np.std(np.array(acc_list))))\n",
    "print('std(f1):{:.3f}'.format(np.std(np.array(f1_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征归一化，留一被试法，平均acc和f1\n",
    "feature_str = ['BIS', 'MIX', 'PE', 'LZC', 'SVD_0', 'SVD_1', 'SVD_2', 'SVD_3']\n",
    "# 降噪前\n",
    "# acc_all = [0.789, 0.839, 0.806, 0.678, 0.773, 0.722, 0.754, 0.705]\n",
    "# f1_all = [0.411, 0.667, 0.624, 0.388, 0.457, 0.477, 0.379, 0.409]\n",
    "# 降噪后\n",
    "acc_all = [0.789, 0.826, 0.807, 0.666, 0.762, 0.768, 0.702, 0.705]\n",
    "f1_all = [0.411, 0.658, 0.630, 0.387, 0.402, 0.412, 0.291, 0.324]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "color_bkp = ['forestgreen', 'darkorange',  'firebrick',\n",
    "                'limegreen', 'royalblue', 'darkgrey', 'forestgreen', 'darkblue', 'purple']\n",
    "x_bar = np.arange(len(acc_all))\n",
    "width = 0.4\n",
    "plt.bar(x_bar-width/2, acc_all, width=width, color=color_bkp[0], edgecolor='k', label='acc')\n",
    "plt.bar(x_bar+width/2, f1_all, width=width, color=color_bkp[1], edgecolor='k', label='f1')\n",
    "plt.bar(x_bar, np.zeros(len(acc_all)), tick_label=feature_str)\n",
    "\n",
    "plt.xticks(fontproperties = 'Arial', size = 14)\n",
    "plt.yticks(fontproperties = 'Arial', size = 14)\n",
    "plt.ylabel('Metrics', font={'family':'Arial', 'size':16})\n",
    "plt.xlabel('Feature', font={'family':'Arial', 'size':16})\n",
    "\n",
    "plt.legend(loc=(1.05, 0.3), ncol=1, edgecolor='k', prop={'family':'Arial', 'size':14})\n",
    "plt.tight_layout()\n",
    "# plt.savefig('figs/loc_roc_class.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
